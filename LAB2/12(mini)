import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# 1️⃣ Data
questions = [
    "Hi",
    "How are you?",
    "What's your name?",
    "What do you do?",
    "Bye"
]
answers = [
    "Hello!",
    "I'm good!",
    "I'm a chatbot.",
    "I talk to people.",
    "Goodbye!"
]
labels = [0, 1, 2, 3, 4]
label_to_answer = {0: "Hello!", 1: "I'm good!", 2: "I'm a chatbot.", 3: "I talk to people.", 4: "Goodbye!"}
# 2️⃣ Tokenize
tokenizer = Tokenizer()
tokenizer.fit_on_texts(questions)
vocab_size = len(tokenizer.word_index) + 1
X = pad_sequences(tokenizer.texts_to_sequences(questions), padding='post')
y = np.array(labels)
# 3️⃣ Model
model = Sequential([
    Embedding(vocab_size, 16, input_length=X.shape[1]),
    Bidirectional(LSTM(16)),
    Dense(len(label_to_answer), activation='softmax')
])
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X, y, epochs=200, verbose=0)
# 4️⃣ Chat function
def get_response(text):
    seq = tokenizer.texts_to_sequences([text])
    pad = pad_sequences(seq, maxlen=X.shape[1], padding='post')
    pred = np.argmax(model.predict(pad, verbose=0))
    return label_to_answer.get(pred, "I don't understand.")
# 5️⃣ Test
for user_input in ["Hi", "How are you?", "What do you do?", "Bye"]:
    print("You:", user_input)
    print("Bot:",get_response(user_input))
    print("\n")
    
